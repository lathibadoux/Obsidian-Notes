* A 60 - 90 minute, open-ended conversation discussing various pieces of architecture
* Usually the last interview
[[#009.3.1.1 How to excel in this interview]]
[[#009.3.1.2 Common trade-off in data architecture]]
[[#009.3.1.3 Common Patterns you need to be able to identify]]

## 009.3.1.1 How to excel in this interview
* Stay open-minded
* Ask a lot of follow up questions
	* How accurate does it need to be?
* Understand the trade-offs of the decisions
* Make recommendations that fit the problem at hand
* Don't ask for too many hints

## 009.3.1.2 Common trade-off in data architecture
1. Space vs. Compute
	* Optimizing for space is most important when:
		* IO is very high and network IOPs is high
		* Think OLTP should almost always optimize for space
		* Data is normalized (optimized for space)
	* Optimizing for compute is most important when:
		* Analytical queries are too slow, you can have some redundant storage
		* Think OLAP should almost always optimize for compute
		* Data is denormalized
2. Correctness vs. Latency
	* This tradeoff occurs for a few reasons
		* Streaming pipelines can have late-arriving data, streaming pipelines are harder to enforce data quality
	* Should you optimize for correctness or latency?
		* Depends!
		* Correctness need and data sensitivity are highly correlated
			* healthcare
			* finance
		* Latency-need and site performance are highly correlated
	* Lambda vs. Kappa architecture comes up here a BUNCH
		* Lambda will have highest correctness
		* Kappa will have the lowest latency
3. Reliability vs. Speed
	* Reliable pipelines often process data slower
		* Right-sized partitioning
		* Data quality checks are more comprehensive but more false positive prone
	* Fast pipelines
		* Extra parallelism to reduce landing time
		* Data quality checks only catch catastrophic errors
	* Generally, the higher upstream the dataset, the more quality checks you want.  This is because the further upstream you are, the most downstream pipelines will be affected by errors.
4. Efficiency vs. Capabilities
	* Should we hold onto A LOT of extra data "just in case"?
		* Maybe, it depends on the use case
	* Long retention capabilities that are worth it:
		* Legal defense
		* Anonymized long-term analysis on dimensional aggregates
			* Allows you to do long-term trend analysis
			* SCD type 2
	* Long retention capabilities that usually aren't worth it:
		* Anonymized long-term analysis on fact-level data

## 009.3.1.3 Common Patterns you need to be able to identify
1. Lambda vs. Kappa architecture (what's a better fit?)
	* Kappa
		* Streaming-first
		* Optimizes for simplicity and latency
	* Lambda
		* Streaming and batch versions of pipelines
		* Complicated to maintain
		* Optimizes for correctness and latency
2. Brewers CAP Theorem
	* Should you give up consistency, availability, or partition tolerance?
	* Distributed systems concept
	* You have to pick two
		* consistent and available
			* ex. Postgres - doesn't scale at very high volumes ==Parition Tolerance Fail==
		* availability and partition-tolerant
			* ex. Cassandra - "eventually consistent" ==Consistency Fail==
		* consistency and partition-tolerant
			* ex. MongoDB - will make you want until updates are finished ==Availability Fail==
![[2025-09-09 16_33_49-Settings.jpg]]

3. OLTP use cases vs OLAP use cases
	* OLTP
		* database that supports an application
		* small reads (very filtered down)
		* usually only have the most recent data
		* lots of concurrent queries (lots of users)
		* RestAPIs
	* OLAP
		* huge reads
		* few concurrent queries
		* historical data too
		* where data engineers usually work
4. How to correct inconsistencies
	* Are inconsistencies acceptable?
	* Diverging inconsistencies can grow if left to fester
	* CRON job in the OLAP space with the most up-to-date info can "true up" online systems