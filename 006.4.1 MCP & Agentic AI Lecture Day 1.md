[[#006.4.1.1 AI Usage Pyramid]]
[[#006.4.1.2 MCP Servers vs Tools]]
[[#006.4.1.3 How to connect to an MCP server]]
[[#006.4.1.4 How many tools is too many tools]]
### 006.4.1.1 AI Usage Pyramid

![[AI_Pyramid.jpg]]


**Bottom Layer: Prompting ChatGPT**
* Everyone does this.  Gets synthesis value.  AI doesn't do much more than advise and inform

**Second Layer: Using Python to Prompt ChatGPT**
* Same as prompting from the web UI except now you get to feel special for using Python
* You can prompt it in more dynamic ways than you can with ChatGPT
* The RAGs of the world

**Third Layer: Using tools + Prompt**
* Now you're playing with **Fire** and your AI can truly break things
* It can hallucinate and bring down production

**Fourth Layer: MCP**
* Now your AI can be unleashed to its full capabilities

**Top Layer: Agents**
* You can now tie it all together and build "autonomous agents" and automate yourself out of a job

**==Without tools, AI is nothing but a professor, therapist, a best friend, and a poet!==**

---
### 006.4.1.2 MCP Servers vs Tools
### Extremely basic tool example

![[extremely_basic_tool_example.jpg]]

* When you register a tool, it gets put into the context window ==every time==.
* Every time you make a call, those input tokens will be used.  If you have a lot of tools, it can use resources really quickly.  It can also confuse the AI.

**Manually registering every tool can be a huge pain!**

**This is where MCP servers come into the picture!**
![[MCP_server_vs_tools.jpg]]
* If you connect to an MCP server or you manually define a tool; they both do the same thing.
* The difference is who handles what thing.
* When MCP is done correctly, it is amazing.  However, if it breaks, you can't really make it better.
* You maintain all the control over the tools.

**MCP Service Diagram**
![[MCP_service_diagram.jpg]]

**==For simple AIs, MCP can be overkill!  Just add one tool!==**

---
### 006.4.1.3 How to connect to an MCP server

* Depends on the protocol:
	* For Remote HTTP MCP servers:
		* You connect via ==the /mcp endpoint and auth with either Oauth2 or API tokens (see in Day 1 lab)==
	* For stdin/stdout for local MCP servers (better for privacy)
	* Via docker with stdin/stdout exposed

---
### 006.4.1.4 How many tools is too many tools

* MCP servers can accidentally flood the context window with too many options ==(this causes a higher chance of hallucination!)==
* Once you're above 10 tools, ==consider a multi-agent architecture (see Day 2 lab)==
* The fewer the tools in the context the faster, better performing, and cheaper the AI will be.

**Best Practices Continued**
* Best practices from Full Stack Development
	* Don't have the "God" agent.  Separate agents for easier testability
	* Version your tools
	* Persist session state
		* LangChain does this for you for free
	* Always enable authentication


