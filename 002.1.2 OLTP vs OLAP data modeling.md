* OLTP (online transaction processing)
	* Optimizes for low-latency, low volume queries
	* Mostly out of the realm of data engineering
	* Where software engineers model data to make their online systems as efficient as possible
	* Lots of constraints
	* Will need to do a lot of joins to get the data you want
	* Really care about removing duplicates
	* Looking at one user / one entity
* OLAP (online analytical processing)
	* Optimizes for large volume, GROUP BY queries, minimizes JOINs
	* The most common data modeling that data engineers use
	* Don't care about duplicates
	* Mostly care if we can run a query fast and if we can join two things together
	* Looking at the entire population
	* Not normalized
	* Slice and dice
	* The space data analysts and scientists love
* Master Data
	* Middle ground between OLTP and OLAP
	* Optimizes for completeness of entity definitions, deduped
	* Ex. taking production database snapshots into one table for analysis

**OLTP and OLAP is a continuum: Four layers of data modeling:
![[2025-09-02 13_11_39-Screenshots - File Explorer.jpg]]
1. Production Database Snapshot
	Ex. All transactional data from the AirBnB app
2. Master Data
	Ex. All the transactional data sets merged together to easily understand pricing and availability at AirBnB
	* Normalized
	* Deduped
3. OLAP Cubes
	Ex. Group and aggregate so that you don't have multiple rows per entity.  You can do analytics by country, etc.
4. Metrics
	Ex. The average listing price of all of AirBnB (one number)
